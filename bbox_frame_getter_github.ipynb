{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "damaged-insured",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brutal-ferry",
   "metadata": {},
   "source": [
    "## Necessary paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "moving-clearing",
   "metadata": {},
   "outputs": [],
   "source": [
    "#main folder\n",
    "root_path = \"\"\n",
    "\n",
    "#folder to store bounding boxes and frames\n",
    "path_bounding_boxes_frames = \"\"\n",
    "#folder to store dat and npy files\n",
    "path_dat_npy_files =   \"\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legislative-wiring",
   "metadata": {},
   "source": [
    "## Finding .dat files in our folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "weekly-humor",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Changing to dat_npy_files directory\n",
    "os.chdir(path_dat_npy_files)\n",
    "\n",
    "#We write txt file with the paths of the dat.files we used in root folder\n",
    "used_dat_files_txt = open(f\"{root_path}\" + \"/used_dat_files.txt\",\"w\")\n",
    "\n",
    "\n",
    "\n",
    "for current_dir, dirs, files in os.walk('.'):\n",
    "    # Going through all files\n",
    "    for f in files:\n",
    "        # Checking if filename ends with '.dat'\n",
    "        if f.endswith('dat'):\n",
    "            #Saving dat file each to the txt fil\n",
    "            used_dat_files_txt.write(path_dat_npy_files + f\"/{f}\\n\")\n",
    "            \n",
    "used_dat_files_txt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "based-petroleum",
   "metadata": {},
   "source": [
    "## Data visualizer, frame and bounding boxes extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "increased-eligibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import cv2\n",
    "import argparse\n",
    "from glob import glob\n",
    "\n",
    "from src.visualize import vis_utils as vis\n",
    "\n",
    "from src.io.psee_loader import PSEELoader\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def play_files_parallel(td_files, labels=None, delta_t=20000, skip=0,count_dat_file = 0):\n",
    "    \"\"\"\n",
    "    Plays simultaneously files and their boxes in a rectangular format.\n",
    "    \"\"\"\n",
    "    # open the video object for the inSput files\n",
    "    videos = [PSEELoader(td_file) for td_file in td_files]\n",
    "    # use the naming pattern to find the corresponding box file\n",
    "    box_videos = [PSEELoader(glob(td_file.split('_td.dat')[0] +  '*.npy')[0]) for td_file in td_files]\n",
    "\n",
    "    height, width = videos[0].get_size()\n",
    "    print(\"Hola\",height,width)\n",
    "    labelmap = vis.LABELMAP if height == 240 else vis.LABELMAP_LARGE\n",
    "\n",
    "    # optionally skip n minutes in all videos\n",
    "    for v in videos + box_videos:\n",
    "        v.seek_time(skip)\n",
    "\n",
    "    # preallocate a grid to display the images\n",
    "    size_x = int(math.ceil(math.sqrt(len(videos))))\n",
    "    size_y = int(math.ceil(len(videos) / size_x))\n",
    "    frame = np.zeros((size_y * height, width * size_x, 3), dtype=np.uint8)\n",
    "\n",
    "    cv2.namedWindow('out', cv2.WINDOW_NORMAL)\n",
    "    \n",
    "    count = 0 \n",
    "\n",
    "    # while all videos have something to read\n",
    "    while not sum([video.done for video in videos]):\n",
    "\n",
    "        # load events and boxes from all files\n",
    "        events = [video.load_delta_t(delta_t) for video in videos]\n",
    "        box_events = [box_video.load_delta_t(delta_t) for box_video in box_videos]\n",
    "        \n",
    "        #Save boxes of each frame to a text file\n",
    "        bboxes_file = open(path_bounding_boxes_frames + f\"/prophesee_image_{count_dat_file}_{count}.txt\",\"w\")\n",
    "            \n",
    "        for box in box_events:\n",
    "            bboxes_file.write(f\"{box}\\n\")\n",
    "        \n",
    "        bboxes_file.close()\n",
    "            \n",
    "           \n",
    "        for index, (evs, boxes) in enumerate(zip(events, box_events)):\n",
    "            y, x = divmod(index, size_x)\n",
    "            # put the visualization at the right spot in the grid\n",
    "            im = frame[y * height:(y + 1) * height, x * width: (x + 1) * width]\n",
    "            # call the visualization functions\n",
    "            im = vis.make_binary_histo(evs, img=im, width=width, height=height)\n",
    "\n",
    "            #vis.draw_bboxes(im, boxes, labelmap=labelmap)\n",
    "            \n",
    "           \n",
    "\n",
    "        # display the result\n",
    "        \n",
    "        cv2.imshow('out', frame)\n",
    "        cv2.imwrite(path_bounding_boxes_frames + f'/image_{count_dat_file}_{count}.jpg',frame)\n",
    "        cv2.waitKey(1)\n",
    "        \n",
    "        count += 1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brave-navigator",
   "metadata": {},
   "source": [
    "## Extracting frames and bounding boxes for each .dat file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "invisible-delay",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Back to main path, just in case\n",
    "os.chdir(root_path)\n",
    "\n",
    "count_dat_file = 0\n",
    "\n",
    "#Reading used_dat_files.txt first\n",
    "used_dat_files = open(f\"{root_path}\" + \"/used_dat_files.txt\",\"r+\")\n",
    "\n",
    "dat_files = used_dat_files. readlines()\n",
    "#We have to pass the .dat paths as a list\n",
    "#We apply the extractor to each file:\n",
    "\n",
    "paths = []\n",
    "for dat_file in dat_files:\n",
    "    paths.append(dat_file[:-1])\n",
    "    \n",
    "for i in range(len(paths)):\n",
    "        try:\n",
    "            \n",
    "           play_files_parallel([paths[i]], labels=None, delta_t=50000, skip=0,count_dat_file=count_dat_file)\n",
    "        except:\n",
    "           pass\n",
    "        count_dat_file += 1 \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reserved-joint",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
